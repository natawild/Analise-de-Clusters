---
title: "Trabalho Prático II - "
author: "Grupo 4"
date: "`r format(Sys.Date(), '%d/%B/%Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r diabetes, message=FALSE, warning=FALSE}
library(readr)
diabetes <- read_csv("diabetes.csv")
attach(diabetes)

```


# Apresentação do caso de estudo

Este *dataset* foi extraido do Kaggle, inicialmente retirado do Instituto Nacional de Diabetes e Doenças Digestivas e Renais dos Estados Unidos. O objetivo do estudo do conjunto de dados em questão seria prever se um paciente tem ou não diabetes, baseado em determinadas medidas de diagnóstico incluídas no dataset. Assim, neste, são alvo de estudo pacientes do género feminino com pelo menos 21 anos de idade e origem da povoação indigena Pima.


## O que é diabetes  

A diabetes é uma doença metabólica crónica que se caracteriza por estados de hiperglicemia (níveis elevados de açúcar no sangue) constantes, os quais resultam de uma deficiência na produção/ secreção de insulina (hormona que atua na regulação da glicemia), de uma alteração na sua ação ou de ambas, resultando num metabolismo anormal dos macronutrientes ingeridos através da alimentação.  

De um modo geral, a doença pode ser classificada em 3 categorias:  

* Diabetes tipo 1: é uma doença autoimune, na qual o próprio sistema imune destrói as células pancreáticas produtoras de insulina. Por esse motivo, é também chamada de insulino-dependente, uma vez que a sobrevivência da pessoa depende da administração de insulina exógena;  

  

* Diabetes tipo 2: devida à perda de função progressiva das células pancreáticas produtoras de insulina, resultando numa expressão menor de insulina. Está intimamente relacionada com a obesidade ou excesso de peso, maus hábitos alimentares e elevados níveis de sedentarismo;  

  

* Diabetes gestacional: quando a anormalidade na glicemia é diagnosticada no 2º ou 3º trimestre da gravidez, sem diabetes prévia à gestação;  

  

Existem ainda outros tipos específicos, associados a doenças que afetam a porção exócrina do pâncreas como fibrose cística, pancreatite ou induzidos por medicamentos como corticoides, imunossupressores ou anti-retrovirais, mas estes não são tão comuns.   

  

Os valores de referência da diabetes ajudam a estabelecer condições de normoglicemia, hiperglicemia ou hipoglicemia e a fazer o diagnóstico da doença.   

  

* NORMOGLICEMIA- É o mesmo que dizer que os valores da glicose estão dentro da normalidade. Para que os valores sejam considerados normais, a glicose deve estar os 80 mg/dl e os 140 mg/dl, dependendo se a análise foi feita em jejum ou após a refeição.  

  

* HIPERGLICEMIA - Acontece quando os valores da glicose ultrapassam os valores normais, ou seja, os níveis de açúcar no sangue são altos. Isto acontece por três razões: o organismo produz insulina a menos, o organismo não utiliza bem a insulina ou uma combinação das duas.   

  

* HIPOGLICEMIA - Por outro lado, quando os valores de açúcar estão baixos demais, os doentes podem ter sintomas como tremores, suores, fraqueza, batimentos cardíacos rápidos ou fortes, tonturas, visão dupla ou desmaios. Se não for detetada e tratada pode ter ainda consequências mais graves como lesões cerebrais ou morte. Se ingerir algo doce, como um sumo de fruta, os valores devem voltar à normalidade.  

  

A tabela abaixo explica os valores de glicose 2 horas após a refeição   
  

| VALORES DE REFERÊNCIA 2 HORAS APÓS A REFEIÇÃO |              | 
|-----------------------------------------------|--------------| 
| inferior 70 mg/dl                             | hipoglicemia | 
| 70 mg/dl a 140 mg/dl                          | normal       | 
| 140 mg/dl a 199 mg/dl                         | pré-diabetes | 
| superior 200 mg/dl                            | diabetes     | 


# Análise do *Dataset*

## Descrição dos dados


O *dataset* contém informação de 768 mulheres, das quais 268 foram diagnosticadas com diabetes. As informações disponíveis incluem 8 variáveis, tais como Idade, Número de gestações, Glicose, Insulina, etc. Uma descrição mais detalhada sobre as variáveis está exposta nos pontos abaixo. A variável resposta no conjunto de dados é um classificador binário, *Outcome*, que indica se a pessoa foi diagnosticada com diabetes ou não.


* **Pregnancies**: Número de vezes que engravidou

* **Glucose**: Concentração de glicose no plasma durante 2 horas presente num teste de tolerância à glicose por via oral

* **BloodPressure**: Pressão sanguínea diastólica (mm Hg)

* **SkinThickness**: Espessura da dobra da pele do tríceps (mm)

* **Insulin**: Insulina sérica de 2 horas (mu U/ml) (ISTO É VERDADE???)

* **BMI**: índice de massa gorda (weight in kg/(height in m)2)

* **DiabetesPedigreeFunction**: Função de hereditariedade da diabetes (uma função que pontua a probabilidade de diabetes com base no histórico familiar)

* **Age**: Idade (anos)

* **Outcome**: Variável de classe (0 se não diabético, 1 se diabético)


### **Variável dependente**

Uma variável dependente é uma medida que dependerá do valor de outra(s) medida variável. Na regressão logística, a variável resposta é dicotómica (*Outcome*), atribuindo-se o valor 1 ao acontecimento de ter diabetes (sucesso) e 0 ao acontecimento complementar (insucesso), ou seja, esta variável define se o paciente possuí ou não a doença diabetes.


#### **Variáveis Independentes**

Uma variável independente é uma medida que não depende de nenhuma outra medida, sendo que existem 8 variáveis deste tipo no modelo. Foram consideradas variáveis tais como o número de gravidezes, a concentração de glicose no plasma, a pressão sanguínea diastólica (mm Hg), a espessura da pele do trícepe (mm), o nível de insulina durante as 2 horas de teste (mu U/ml), o índice de massa corporal (peso (kg)/ altura (m)^2), a função de linhagem de diabetes e a idade em anos.


### Criação da variável "*Outcome*" como fator 

Uma vez que no *dataset* em estudo a variável resposta se trata de uma binária (0 e 1), foi necessário cria um fator para a mesma.

Para criar a variável como fator utilizou-se a função "factor", na qual o único argumento necessário é um vetor de valores. O argumento "levels" determina as categorias da variável fator, sendo o padrão atribuido o correpondente: 0, ou seja, não possuir diabetes fica representado por "Não" e 1, ter diabetes, representado por "Sim".

```{r criacao fator}
Outcome <- factor(diabetes$Outcome)
levels(Outcome) <- c("Não", "Sim")
is.factor(Outcome)
summary(Outcome)
```

### Gráfico do *MissMap*
Numa primeira fase tentou-se perceber os *missing values* existentes no *dataset*. Para tal criou-se um gráfico, *missmap* que ajuda a verificar esses mesmos valores. 

```{r amelia}
library(Amelia)

sapply(diabetes, function (x) sum(is.na(x)))

#saber se existem missing values
data<- subset(diabetes,select=c(1,2,3,4,5,6,7,8,9))
missmap(data, main = "Missing values vs observed")
```

Da análise desse gráfico conclui-se que não existiam valores em falta efetivos (?). Uma vez melhor analisado percebeu-se que existiam muitos zeros no modelo que não fariam sentido para o mesmo, nomeadamente nas variáveis Glucose, Insulin, SkinThickness, BMI e Bloodpressure, uma vez que registos com zero nestas variávies não fazem sentido.


# Tratamento de dados 
### Substituição dos Zeros em "NA"
Nesta fase surgiu a necessidade de limpar o *dataset*, uam vez que após uma análise mais profunda, o conjunto de dados revelou muitos valores anormais para medidas biológicas, isto é, existiam variáveis como a espessura da pele e a glicose que apresentaram 227 e 374 valores zero, respectivamente.  Desta forma, sabe-se que este valor indica ausência de valor e não valor zero propriamente. Os valores ausentes no conjunto de dados constituíram cerca de 30% das observações no conjunto de dados, o que levou a pensar que a remoção desses valores resultaria numa perda significativa de informações, então o que foi feito foi:

* Transformar os zeros em NA
* Transformar os NA na média daquela coluna

Realçando o facto de que a variável da gravidez tem efetivamente 0 gravidezes e nesta variável não foi substituído o zero pela média. Desta forma conseguiu-se remover os zeros (que não faziam sentido) e conseguir assim, um *dataset* limpo e pronto a explorar.

```{r tratamento de dados, message=FALSE, warning=FALSE}
library(lattice)
missing_data <- diabetes[,setdiff(names(diabetes), c('Outcome', 'Pregnancies'))]
features_miss_num <- apply(missing_data, 2, function(x) sum(x <= 0))
features_miss <- names(missing_data)[ features_miss_num > 0]

rows_miss <- apply(missing_data, 1, function(x) sum(x <= 0) >= 1) 
sum(rows_miss)

missing_data[missing_data <= 0] <- NA
diabetes[, names(missing_data)] <- missing_data
```

### Gráfico com os *missing values*

```{r data missing values}
library(Amelia)

sapply(diabetes, function (x) sum(is.na(x)))
datanovo<- subset(diabetes,select=c(1,2,3,4,5,6,7,8,9))
missmap(datanovo, main = "Missing values vs observed")

```



```{r tratamento de dados novo, message=FALSE, warning=FALSE}
# KNN imputation
orig_data <- diabetes
colSums(is.na(diabetes))


#diabetes[,c(-8)] 
#diabetes <- diabetes[,c(-8)]

diabetes$Glucose[is.na(diabetes$Glucose)] <- mean(diabetes$Glucose,na.rm=T)
diabetes$Insulin[is.na(diabetes$Insulin)] <- mean(diabetes$Insulin,na.rm=T)
diabetes$SkinThickness[is.na(diabetes$SkinThickness)] <- mean(diabetes$SkinThickness,na.rm=T)
diabetes$BMI[is.na(diabetes$BMI)] <- mean(diabetes$BMI,na.rm=T)
diabetes$BloodPressure[is.na(diabetes$BloodPressure)] <- mean(diabetes$BloodPressure,na.rm=T)
```

```{r}
library(ggplot2)
ggplot(diabetes,aes(Outcome,fill = factor(diabetes$Outcome))) +
  geom_bar() + 
  labs (fill = "Legenda") +
  geom_text(stat='count', aes(label=..count..),vjust=0,size=5,nudge_y=0.125) +
  
  ggtitle("Distribuição da variável Outcome")
```




## Análise da variável "Pregnancies"
```{r barplotGravidez}
grav <- c(111, 135,103,75,68,57,50,45,38,28,24,11,9,10,2,1,1)
 b <- barplot(grav,
 main = "Gravidez",
 xlab = "Número de gravidezes",
 ylab = "Número de pacientes",
 ylim = c(0,150),
 names.arg = c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,17),
 col = c("lightblue"),
 col.main="blue",
 horiz = FALSE)
text(b,grav+10,labels=as.character(grav))
```


## Gráficos que relacionam a Gravidez com o resultado
```{r gravidez, message=FALSE, warning=FALSE}
table(Pregnancies, factor(diabetes$Outcome))

library(ggplot2)
p1 <- ggplot(diabetes, aes(x = factor(diabetes$Outcome), y = Pregnancies, fill = factor(diabetes$Outcome))) +
  geom_boxplot() +  
  theme(legend.position = "bottom") +
  labs (x = "Resultado") + labs (y ="Número de Gravidezes" ) + labs (fill = "Legenda") +
  ggtitle("Número de gravidezes Vs Diabetes")


p2 <- ggplot(diabetes,aes(x = Pregnancies, fill = factor(diabetes$Outcome))) + 
  geom_bar(position = "Dodge") + 
  scale_x_continuous(limits = c(-1,17)) +
  labs (x = "Resultado") + 
  labs (fill = "Legenda") +
  theme(legend.position = "bottom") +
  labs(title = "Gravidez Vs Resultado") +
  geom_text(stat='count', aes(label=..count..),vjust=0,size=3,nudge_y=0.125)


library(gridExtra)
gridExtra::grid.arrange(p1, p2, ncol = 2)
```


## Análise da variável "Glucose"

```{r glicose, message=FALSE, warning=FALSE}
p2 <- ggplot(diabetes, aes(x = Glucose, fill = factor(diabetes$Outcome))) +
  geom_density(alpha = 0.8) +
  theme(legend.position = "bottom") +
  labs (fill = "Legenda") +
  labs(x = "Glicose", y = "Densidade", title = "Gráfico de densidade da glicose")

p1 <- ggplot(diabetes, aes(x = Outcome, y = Glucose,fill = factor(diabetes$Outcome))) +
  geom_boxplot() +
  theme(legend.position = "bottom") +
  labs (fill = "Legenda") +
  ggtitle("Variação da glicose Vs Diabetes")

gridExtra::grid.arrange(p1, p2, ncol = 2)
```


## Análise da variável "Blood Pressure"

```{r blood pressure, message=FALSE, warning=FALSE}

p2 <- ggplot(diabetes, aes(x = BloodPressure, fill = factor(diabetes$Outcome))) +
  geom_density(alpha = 0.8) +
  theme(legend.position = "bottom") +
  labs (fill = "Legenda") +
  labs(x = "Pressão Sanguínea", y = "Densidade", title = "Gráfico de densidade vs Diabetes")

p1 <- ggplot(diabetes, aes(x = factor(diabetes$Outcome), y = BloodPressure,fill = factor(diabetes$Outcome))) +
  geom_boxplot() +
  theme(legend.position = "bottom") +
  labs (fill = "Legenda") +
  ggtitle("Pressão Sanguínea Vs Diabetes")

gridExtra::grid.arrange(p1, p2, ncol = 2)

```

## Análise da variável "SkinThickness"

```{r skinthickness, message=FALSE, warning=FALSE}
ggplot(diabetes, aes(x = SkinThickness, fill = factor(diabetes$Outcome))) +
  geom_density(alpha = 0.8) +
  theme(legend.position = "bottom") +
  labs (fill = "Legenda") +
  labs(x = "Espessura da pele", y = "Densidade", title = "Gráfico de densidade")
```




## Análise da variável Insulina
```{r var insulina, message=FALSE, warning=FALSE}
library(ggplot2)
ggplot(diabetes, aes(x = factor(diabetes$Outcome), y = Insulin ,fill = factor(diabetes$Outcome))) +
  geom_boxplot() + 
  theme(legend.position = "bottom") +
   labs (x = "Resultado") + labs (y ="Insulina" ) + labs (fill = "Legenda") +
  ggtitle("Boxplot Insulina vs Diabetes")
```

## Análise da variável BMI
O Índice de Massa Corporal (IMC) é um índice usado para a classificação do peso corporal em adultos, que relaciona o peso com a altura. A fórmula deste índice é definida pelo peso do indivíduo (em kilogramas) dividido pelo quadrado da sua altura (em metros). IMC= peso (kg) /altura (m)×altura (m).  

A Organização Mundial de Saúde (OMS) classifica a obesidade de acordo com os seguintes critérios: 

| Classificação    | IMC (kg/m2) | 
|------------------|-------------| 
| Baixo Peso       | ≤ 18,5      | 
| Peso normal      | 18,5 a 24,9 | 
| Pré-obesidade    | 25 a 29,9   | 
| Obesidade grau 1 | 30 a 34,9   | 
| Obesidade grau 2 | 35 a 39,9   | 
| Obesidade grau 3 | ≥ 40        | 


```{r bmi, message=FALSE, warning=FALSE}

p2 <- ggplot(diabetes, aes(BMI, fill = factor(diabetes$Outcome))) +
  geom_histogram() +
  theme(legend.position = "bottom") + 
  labs(fill="Legenda") + labs(y="Quantidade de pacientes")+
  ggtitle("IMC Vs Diabetes")

p1 <- ggplot(diabetes, aes(x = factor(diabetes$Outcome), y = BMI, fill = factor(diabetes$Outcome))) +
  geom_boxplot() +
  theme(legend.position = "bottom") +
  labs(fill="Legenda") + labs (x = "Resultado") + labs (y ="Indice massa corporal" ) + 
  ggtitle("Variação do IMC Vs Diabetes")

gridExtra::grid.arrange(p1, p2, ncol = 2)

```

Pela análise dos gráficos produzidos, é possível verificar que todas as mulheres com diabetes tinham um IMC superior a 25, valor este que está acima dos níveis normais. Podendo-se assim concluir que a obesidade poderá ser um fator de risco para a diabetes.  Por outro lado, as mulheres que não tinham diabetes tinham um IMC variando de 18 a 60. 


## Análise da variável Função genética 

```{r genetica, message=FALSE, warning=FALSE}

p2 <- ggplot(diabetes, aes(DiabetesPedigreeFunction, fill = factor(diabetes$Outcome))) +
  geom_histogram() +
  theme(legend.position = "bottom") + 
  labs(fill="Legenda") + labs(y="Quantidade de pacientes")+
  ggtitle("Função genética Vs Diabetes")

p1 <- ggplot(diabetes, aes(x = factor(diabetes$Outcome), y = DiabetesPedigreeFunction, fill = factor(diabetes$Outcome))) +
  geom_boxplot() +
  theme(legend.position = "bottom") +
  labs(fill="Legenda") + labs (x = "Resultado") + labs (y ="Função genética" ) + 
  ggtitle("Função genética Vs Diabetes") 

gridExtra::grid.arrange(p1, p2, ncol = 2)

```



## Relação da Gravidez com a idade vs diabetes
```{r idade vs diabetes}
p1 <- ggplot(diabetes, aes(x = Age, y = Pregnancies)) +
  geom_point(aes(color=Outcome)) + 
  theme(legend.position = "bottom") +
  ggtitle("Influência da idade com a gravidez")

p2 <- ggplot(diabetes,aes(x=Insulin,y=Glucose))+
  geom_point(aes(color=Outcome))+
  theme(legend.position = "bottom") +
  ggtitle("Influência da insulina com a glicose")

gridExtra::grid.arrange(p1, p2, ncol = 2)
```

```{r }
p1 <- ggplot(diabetes,aes(x=BMI,y=BloodPressure))+
  geom_point(aes(color=Outcome))+
  theme(legend.position = "bottom") +
  ggtitle("Relação do IMC com a BP ")

p2 <- ggplot(diabetes,aes(x=BMI,y= DiabetesPedigreeFunction))+
  geom_point(aes(color=Outcome))+
  theme(legend.position = "bottom") +
  ggtitle("Relação do IMC com a função hereditariedade")

gridExtra::grid.arrange(p1, p2, ncol = 2)
```




### Matriz de correlação 

A matriz de correlação mostra os valores de correlação de *Pearson*, que medem o grau de relação linear entre cada par de variáveis. Os valores de correlação variam entre -1 e +1, em que -1 significa uma correlação negativa entre as variáveis, ou seja, quando uma aumenta a outra diminui e 1 significa uma correlação positiva. 

```{r matriz}
library(corrplot)
matriz <- diabetes[, c(1,2,3,4,5,6,7,8)]
res<- cor(matriz)
round(res,2)
corrplot(res, method = "circle")
```

Pela análise da matriz percebe-se que nenhuma das variáveis se encontram fortemente correlacionadas. As variáveis com maior correlação entre elas é a *Age*  e  a *Pregnancies*, ou seja, a idade e o número de vezes que a pessoa esteve grávida, sendo o coeficiente de correlação de 0.54 (superior a 0.5).  Para além disto, existem variáveis que se relacionam de forma um pouco mais acentuada com a variável reposta, as quais: *Glucose*, *BMI* e a *SkinThickness*, por ordem decrescente de correlação. 


# Modelação  - Regressão logística

A técnica de modelação utilizada neste trabalho foi a regressão logística. A regressão logística é uma técnica estatística que tem como objetivo criar um modelo capaz de prever valores tomadas por uma variável categórica, normalmente binária, a partir de um conjunto de variáveis contínuas e/ou binárias. 

O *dataset* foi dividido em 70% para treino e 30% para teste. 

```{r train-test}
library(caret)
library(ggplot2)

# Prep Training e Test
set.seed(100)
trainDataIndex <- createDataPartition(Outcome, p=0.7, list = F) # 70% training data
train <- diabetes[trainDataIndex, ]
test <- diabetes[-trainDataIndex, ]
```


O modelo foi criado utilizando a variável *Outcome* como variável resposta e as restantes 8 como variáveis preditoras. 

```{r model}
#Modelo
model <- glm(Outcome ~.,family=binomial(link='logit'),data=train)
summary(model)
```

Pela análise inicial do modelo criado com todas as variáveis, é possível perceber que existem quatro variáveis mais significativas para o modelo, são elas a *Pregnancies*, *Glucose*, *BMI* e *DiabetesPedigreeFunction*, uma vez que têm p-values inferiores a 0.01. Todas as variáveis com valores superior de p-values deveriam ser retiradas do modelo. 

Como forma de melhor conseguir perceber se esta análise está correta decidiu-se utilizar o modelo da regressão gradual de forma a identificar as variáveis mais importantes. 


### Stepwise Regression (Regressão gradual)

A regressão gradual consiste em adicionar e remover iterativamente preditores no modelo preditivo, de forma a encontrar o subconjunto de variáveis que resultam no modelo com melhor desempenho, ou seja, o modelo que reduz o erro de previsão.

Existem 3 formas de o fazer: 

* **Forward selection**: começa sem preditores no modelo e adiciona iterativamente os preditores que mais contribuem. Termina quando a melhoria não é mais estatisticamente significativa. 

* **Backward selection**: começa com todos os preditores no modelo, removendo iterativamente os preditores que menos contribuem. Termina quando encontrar o modelo no qual todos os preditores são estatisticamente significativos. 

* **Stepwise selection**: é uma combinação das duas seleções anteriores. Começa sem preditores e sequencialmente adiciona os preditores que mais contribuem. Depois de adicionar cada variável nova, remove as variáveis que já não proporcionam melhorias ao modelo. 


Para implementar a regressão gradual utilizou-se a função "stepAIC" que permite saber qual o melhor modelo com base no AIC (*Akaike’s Information Criteria*). Este critério estima a qualidade de cada modelo criado para os dados, em relação a cada um dos outros modelos. A opção *direction* permite escolher qual das estratégias aplicar, *backward*, *forward* ou *both* (as duas em conjunto). No final, permite saber qual o melhor modelo. 

```{r aic}
library(tidyverse)
library(caret)
library(leaps)
library(tidyr)
library(dplyr)
library(MASS)

#ajuste completo do modelo 
full.model <- glm(Outcome~.,family=binomial(link='logit'),data=train)
summary(full.model)

#método both 
step.model <- stepAIC(full.model, direction = "both",
                      trace = FALSE)
summary(step.model)

#método backward
step.modelb <- stepAIC(full.model, direction = "backward",
                      trace = FALSE)
summary(step.modelb)

#método forward
step.modelf <- stepAIC(full.model, direction = "forward",
                       trace = FALSE)
summary(step.modelf)

#verificar qual o que tem menor AIC
AIC(step.model)
AIC(step.modelb)
AIC(step.modelf)
```

No fim utiliza-se a função AIC para saber os valores para os 3 modelos. Chegou-se à conclusão que existem dois modelos com o mesmo AIC, de 501.0397, logo escolher qualquer um deles é igual. 


O parâmetro "nvmax" da função "regsubsets" especifica o número máximo de preditores para incorporar no modelo. Devolde vários modelos com diferentes tamanhos até "nvmax". Tem de se comparar os vários modelos de forma a escolher o melhor. Esta função tem a opção "method" que permite escolher *forward*, *backward* e *seqrep* (que é uma combinação das seleções *forward* e *backward*). 

```{r  models}
models <- regsubsets(Outcome~., data=train, nvmax = 8, method = "seqrep")
summary(models)
```

A função "train" tem uma opção "method" que permite escolher um dos seguintes valores: 

* **leapBackward**: para a seleção "backward"

* **leapForward**: para a seleção "forward"

* **leapSeq**: para a seleção "stepwise" 

O parâmetro "nvmax" corresponde ao número máximo de preditores para serem incorporados no modelo. Neste caso, como a base de dados contém 8 variáveis a serem exploradas, o "nvmax" varia entre 1 e 8. Isto permite obter os 8 melhores modelos com tamanhos diferentes, o melhor modelo de 1 variável, de 2 variáveis e assim sucessivamente.  

Utiliza-se a *10-fold cross validation* para estimar o erro médio de previsão (RMSE). Este é usado para comparar os 8 melhores modelos e escolher o melhor, ou seja, o modelo que minimiza o erro médio de previsão. 

O modelo com 4 variáveis é aquele que tem o menor RMSE, sendo assim considerado o melhor modelo.

```{r  coefs}
#cross validation
set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model <- train(Outcome~., data = diabetes,
                    method = "leapBackward",
                    tuneGrid = data.frame(nvmax = 1:8),
                    trControl = train.control)

# precisão do modelo - escolher o menor erro médio de previsão e MAE, R squared quanto maior melhor 
step.model$results

#melhor modelo 
step.model$bestTune

#coeficientes finais do modelo 
coef(step.model$finalModel, 4)
summary(step.model$finalModel)
```

Após a análise do *stepAIC* foi possível obter o modelo final com apenas 4 variáveis. As variáveis formam a expressão final do modelo, representada por: 

 $y = 0.023765092pregnancies + 0.006470141Glucose  + 0.013789972BMI + 0.132996594DiabetesPedigreeFunction$
 
 
#### **Interpretação dos coeficientes obtidos:**

Determinou-se o efeito que os coeficientes exercem sobre a probabilidade de um evento ocorrer:

* Coeficiente positivo aumenta a probabilidade

* Coeficiente negativo diminui a probabilidade


Neste caso, tal como se pode verificar na fórmula acima , todos os coeficientes são positivos, relevando que todos aumentam a probabilidade de contrair a doença da diabetes. Por exemplo: o aumento de uma gravidez faz com que a probabilidade de ter diabetes aumente em 0.023765092.


```{r modelo2}
model2= glm(Outcome~ Pregnancies + Glucose + BMI + DiabetesPedigreeFunction,family=binomial(link='logit'),data=train)
summary(model2)

```

## Interpretando os resultados do modelo de regressão logística

Executando a função anova no modelo é possível analisar a tabela da deviance.  

```{r anova}
anova(model2, test="Chisq")
```

A diferença entre o desvio nulo e o desvio residual mostra como o modelo está em relação ao modelo nulo, ou seja, o modelo que tem apenas a constante. Quanto maior esta diferença, melhor o modelo. A análise da tabela mostra que sempre que se adiciona uma variável há um decréscimo no desvio. Adicionando as variáveis *Pregnancies*, *Glucose*, *BMI* e a *DiabetesPedigreeFunction * há uma redução do desvio residual, apesar de não ser substancial. 




Apesar destas conclusões, é importante referir que as diferenças não são muito elevadas, uma vez que, como já foi explicado anteriormente, o modelo com todas as variáveis e o modelo reduzido produzem resultados muito parecidos. Foi decidido retirar as variáveis pouco significativas porque se considerou que estavam a ... (esqueci-me da palavra)




```{r mcfadden}
library(pscl)
pR2(model2)
```
O índice McFadden R2 pode ser usado para avaliar o ajuste do modelo. Para este modelo, o valor é de 0.2948, o que significa que o modelo é excelente. 



## *Accuracy* do modelo

Inicialmente foi necessário carregar o *package* *yhat* que fornece vários métodos para interpretar resultados de regressão logística. Note-se que o primeiro comando utiliza a expressão *fitted.values* que é uma função genérica que extrai valores ajustados de objetos retornados por funções de modelação, neste caso foi aplicado ao *model2*, ou seja, o objeto para o qual a extração dos valores ajustados do modelo foi significativa.

## Avaliando a capacidade preditiva do modelo

Nas etapas acima, foi avaliado brevemente o ajuste do modelo, agora será necessário ver como o modelo está  ao prever um novo conjunto de dados. Ao definir o tipo de parâmetro = 'resposta',  o "R" produzirá probabilidades na forma de P (y = 1 | X). O limite de decisão será 0,5. Se P (y = 1 | X)> 0,5 então y = 1 caso contrário y = 0.

```{r accuracy}
library(yhat)
yhat=fitted.values(model2)

fitted.results <- predict(model2,newdata=subset(test,select=c(1,2,6,7)),type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != test$Outcome)
print(paste('Accuracy',1-misClasificError))
```

A precisão de 0.75 no conjunto de testes é um bom resultado. No entanto, este resultado depende um pouco da divisão manual dos dados que foi anteriormente feita.


```{r predict}
library(tidyverse) # for data manipulation
library(dlstats)    # for package download stats
library(pkgsearch)
library(ROCR)
library(gplots)


p <- predict(model2, newdata=subset(test,select=c(1,2,6,7)), type="response")
pr <- prediction(p, test$Outcome)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

```


Foi desenhada a curva ROC, que é uma medida típica de desempenho para um classificador binário. 
O ROC é uma curva gerada pela relação da taxa positiva verdadeira (TPR) com a taxa de falsos positivos (FPR) em várias configurações de limite, enquanto a AUC é a área sob a curva ROC.


```{r auc}
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc

```
Foi ainda calculada a AUC (área sob a curva), também ela uma medida de desempenho bastante utilizada.


```{r pri}
library(yhat)
pr_i <- prediction(yhat, train$Outcome)
prf_i <- performance(pr_i, measure = "tpr", x.measure = "fpr")
plot(prf_i)
```


```{r  auci}
auc_i <- performance(pr_i, measure = "auc")
auc_i <- auc_i@y.values[[1]]
auc_i
```
Em geral, um modelo com boa capacidade preditiva deve ter uma AUC mais próxima de 1 (1 é ideal) do que 0.5, logo com o valor de 0.85 está bastante bom.



```{r}

exp(coefficients(model2)) 

```





























